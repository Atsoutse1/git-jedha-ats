{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "colab": {
      "name": "01-Deep_Learning_in_production_solutions.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Atsoutse1/git-jedha-ats/blob/main/01_Deep_Learning_in_production_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zavz_QUbU9OA"
      },
      "source": [
        "# Deep Learning in production\n",
        "\n",
        "We have seen how to push in production a machine learning model. Now, you have to push a deep learning model into production.\n",
        "\n",
        "It is up to you to choose which model you would like to use on this <a href=\"https://www.kaggle.com/prasunroy/natural-images\" target=\"_blank\">Natural images dataset</a>.\n",
        "\n",
        "As a reminder, here are the steps:\n",
        "\n",
        "1. Train your image classifier, you can take the opportunity to use MLFlow so as to track your experimentations,\n",
        "2. Deploy it to SageMaker,\n",
        "3. Start making inferences on test images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKZeOykBU9OI"
      },
      "source": [
        "## Solution\n",
        "\n",
        "First download the dataset and unzip it in your working folder.\n",
        "\n",
        "One may do a little EDA before starting to build any model. Here, we skip this part to stay concise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V35snbnEU9OJ"
      },
      "source": [
        "### Prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLpIb2GTU9OJ"
      },
      "source": [
        "# Change this path before running this notebook\n",
        "DATAS_PATH = \"data/natural_images/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL3RxeRQU9OL"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
        "from keras.models import Sequential\n",
        "import mlflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iEKOMp4U9OM",
        "outputId": "fe920d9b-72ce-46b6-b653-8af2b0613c44"
      },
      "source": [
        "labels = os.listdir(DATAS_PATH)\n",
        "print(\"Labels: \", labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Labels:  ['cat', 'car', 'fruit', 'dog', 'person', 'flower', 'motorbike', 'airplane']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5LmXy1wU9ON"
      },
      "source": [
        "def generate_dataset(labels):\n",
        "    \"\"\"Generate the dataset.\n",
        "\n",
        "    Args:\n",
        "        labels (list[str]): list of labels, which are the same as the folder names\n",
        "\n",
        "    Return:\n",
        "        tuple[list[str], list[str]]: returns two lists X and y, respectively the images \n",
        "            and the labels\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "    for label in labels:\n",
        "        path = os.path.join(DATAS_PATH, label)\n",
        "        folder_data = os.listdir(path)\n",
        "        for image_path in folder_data:\n",
        "            # Read the image\n",
        "            image = cv2.imread(os.path.join(path, image_path))\n",
        "            # Resize the image to fit model input size\n",
        "            image_resized = cv2.resize(image, (32,32))\n",
        "            # Append image and associated label\n",
        "            X.append(np.array(image_resized))\n",
        "            y.append(label)\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3m-IwSOU9OO"
      },
      "source": [
        "X_raw, y_raw = generate_dataset(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ayy7zeEU9OP"
      },
      "source": [
        "# Convert those list into numpy array\n",
        "X_raw = np.array(X_raw)\n",
        "y_raw = np.array(y_raw)\n",
        "print(f\"X shape: {X_raw.shape}\\ny shape: {y_raw.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02yqCKBJU9OQ"
      },
      "source": [
        "# As little preprocessing we standardize the images\n",
        "X = X_raw / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHdd2dzRU9OR"
      },
      "source": [
        "# Process the y in order to get vectors of 0s and 1s\n",
        "y_encoded = LabelEncoder().fit_transform(y_raw)\n",
        "y = to_categorical(y_encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMuwedjOU9OR"
      },
      "source": [
        "# Split into train and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.3,\n",
        "                                                    random_state=42,\n",
        "                                                    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPGXqW4mU9OT"
      },
      "source": [
        "### Define our model\n",
        "\n",
        "It is inspired by <a href=\"http://yann.lecun.com/exdb/lenet/\" target=\"_blank\">LeNet5</a>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqmRDrKvU9OV"
      },
      "source": [
        "def lenet(X_train):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=32, kernel_size=(5,5), activation=\"relu\", input_shape=X_train.shape[1:]))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(rate=0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation=\"relu\"))\n",
        "    model.add(Dropout(rate=0.5))\n",
        "    model.add(Dense(8, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkZdV__UU9OW"
      },
      "source": [
        "model = lenet(X_train)\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwaXDEUzU9OW"
      },
      "source": [
        "### Train\n",
        "\n",
        "Using MLFlow!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffONnnEJU9OX"
      },
      "source": [
        "# Enable auto-logging to MLflow to capture TensorBoard metrics.\n",
        "mlflow.tensorflow.autolog()\n",
        "\n",
        "with mlflow.start_run():\n",
        "    history = model.fit(X_train, y_train, epochs=25, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}